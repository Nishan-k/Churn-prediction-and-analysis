{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4a27ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import load_data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix\n",
    "%matplotlib inline\n",
    "\n",
    "# Pre-processing:\n",
    "from sklearn.utils import resample\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, cross_val_score, cross_validate\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# Ml models:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e97164",
   "metadata": {},
   "source": [
    "# 1. Load the data from the `data_loader`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99c7ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data()\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62cbbbd",
   "metadata": {},
   "source": [
    "## 2. EDA:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1195f1b2",
   "metadata": {},
   "source": [
    "## 2.1 Data dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c98c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are a total of: {df.shape[0]} samples and {df.shape[1]} features in this data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2469ec",
   "metadata": {},
   "source": [
    "`customer_id` won't be relevant for us, so we will drop it now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1252915",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['customer_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8e9429",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2616de1a",
   "metadata": {},
   "source": [
    "## 2.2 Check for NULL values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f663f353",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb6f4b3",
   "metadata": {},
   "source": [
    "We don't have any missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f48fe8",
   "metadata": {},
   "source": [
    "## 2.3 Data info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14267e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d526e6",
   "metadata": {},
   "source": [
    "There are some changes we need to do for the `dtypes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37baedf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['senior_citizen'] = df['senior_citizen'].astype('object')\n",
    "df['monthly_charges'] = df['monthly_charges'].astype('float64')\n",
    "df['total_charges'] = df['total_charges'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeb7a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['churn'] = df['churn'].map({\"Yes\": 1, \"No\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1661a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8de397",
   "metadata": {},
   "source": [
    "## 2.4 Data Exploration with Visualization:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32368c2",
   "metadata": {},
   "source": [
    "It is important to understand the data distribution and most importantly for a classification task i.e. whehter a customer will Churn `1` or Not-Churn `0`, we need to see if we have class imabalance or not. It is quite common to have a class imbalance problem, where the count of one class is higher than the other, which might create problem when building the model. It will create a bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fb101a",
   "metadata": {},
   "source": [
    "### Univariate Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d009af2a",
   "metadata": {},
   "source": [
    "#### Churn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cab8faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['churn'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeca2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(data=df, x='churn', hue='churn')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12d8660",
   "metadata": {},
   "source": [
    "The dataset is imbalanced, `class 0` is dominating the count."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aa2df5",
   "metadata": {},
   "source": [
    "When training the model in the later stage, I will use two versions of dataset:\n",
    "1. This normal imbalanced dataset.\n",
    "2. A balanced dataset which will be handled using `Oversampling technique`.\n",
    "\n",
    "And then compare the results and choose the data accordingly but use of imbalanced data will most defnitely create the problem, so lets find out later on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc142ba",
   "metadata": {},
   "source": [
    "Now, i will use a resample technique and handle the class imbalance and keep this data set separately to try out at the later stage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ef9279",
   "metadata": {},
   "source": [
    "#### Handling class imbalance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffd502c",
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_class = df[df['churn'] == 0]\n",
    "minorty_class = df[df['churn'] == 1]\n",
    "\n",
    "minority_oversampled = resample(minorty_class, replace=True, n_samples=len(majority_class), random_state=42)\n",
    "df_balanced = pd.concat([majority_class, minority_oversampled])\n",
    "\n",
    "# To shuffle the data to introduce randomness:\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81846b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(data=df_balanced, x='churn', hue='churn')\n",
    "plt.title(\"Class Balanced\")\n",
    "plt.legend(loc='lower left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826774eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced85238",
   "metadata": {},
   "source": [
    "Now, we have a balanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd48abf",
   "metadata": {},
   "source": [
    "#### Numerical Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2b80fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=(7, 4))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d8ff1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind='density', subplots=True, layout=(3, 2), figsize=(7, 6), sharex=False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507523b0",
   "metadata": {},
   "source": [
    "We can see that most of the clients are young."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbbc565",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind='box', subplots=True, layout=(2, 2), figsize=(7, 6))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11c21f2",
   "metadata": {},
   "source": [
    "#### Gender:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef883b27",
   "metadata": {},
   "source": [
    "Customer involvement by gender:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b75678",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=df['gender'].value_counts().index, \n",
    "            y=df['gender'].value_counts().values, \n",
    "            hue=df['gender'].value_counts().index)\n",
    "plt.title(\"Customer Involvement by Gender\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d9b0b0",
   "metadata": {},
   "source": [
    "#### Contract:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb4e285",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5.6))\n",
    "ax = sns.barplot(x=df['contract'].value_counts().index,\n",
    "                 y=df['contract'].value_counts().values,\n",
    "                 hue=df['contract'].value_counts().index\n",
    "                )\n",
    "\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{int(p.get_height())}', \n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='center', \n",
    "                xytext=(0, 9), textcoords='offset points')\n",
    "\n",
    "plt.title(\"Customer Counts on Contract Basis\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1d3c61",
   "metadata": {},
   "source": [
    "This dataset has no any date columns else we could assume how long they have been in the business. If it has been for a short time then this chart shows the company is doing well as the contract for one year and two years are there which shows some level of trust and satisfaction but if the company is old then we need to come up with some strategies to turn customers from month-to-month subscription ot one or more year contract."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59858c1f",
   "metadata": {},
   "source": [
    "#### Tenure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdc60a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['tenure'], bins=10)\n",
    "plt.title(\"Tenure Histogram Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada6b282",
   "metadata": {},
   "source": [
    "Here, is an interesting pattern, there are customers who have been with the company for past 70 months, and there are new batch of customer who are at their first experience ranging from their first to their fifth month of subscription. So, this shows, the company has been running their services for a long time and clears out doubt for earlier chart."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf58e0a6",
   "metadata": {},
   "source": [
    "#### Customer Marriage Status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6ffd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 6))\n",
    "ax = sns.barplot(x=df['partner'].value_counts().index,\n",
    "                y=df['partner'].value_counts().values,\n",
    "                hue=df['partner'].value_counts().index)\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{int(p.get_height())}', \n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='center', \n",
    "                xytext=(0, 9), textcoords='offset points')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2611e9e",
   "metadata": {},
   "source": [
    "# 3. Data Pre-processing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8d1d81",
   "metadata": {},
   "source": [
    "In the categorical data that we have, there is no any Ordinal data, and these categorical columns also don't have too much of cardinality, so, here I will be using `One-hot Encoding`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33cce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_encoding(df):\n",
    "    X = df.iloc[:, 0:-1]\n",
    "    y = df.iloc[:, -1].astype(int)\n",
    "    numerical_df = X.select_dtypes(include=['int64', 'float64'])\n",
    "    \n",
    "    categorical_df = X.select_dtypes(include=['object'])\n",
    "    categorical_cols = categorical_df.columns\n",
    "    transformers = [(col, OneHotEncoder(), [col]) for col in categorical_cols]\n",
    "    \n",
    "    column_transformer = ColumnTransformer(transformers=transformers, remainder='passthrough')\n",
    "    encoded_data = column_transformer.fit_transform(X)\n",
    "    encoded_df = pd.DataFrame(encoded_data, columns=column_transformer.get_feature_names_out())\n",
    "    \n",
    "    \n",
    "    return encoded_df, y, numerical_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de368f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, numerical_df = data_encoding(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab329e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_balanced, y_balanced, numerical_df_balanced = data_encoding(df_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e583d587",
   "metadata": {},
   "source": [
    "Here, I have encoded both, the original imbalanced and the balanced dataset. And numerical data has been separated for correlation and Mult-collinearity:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abbb2a1",
   "metadata": {},
   "source": [
    "# 4. Correlation and Multi-Collinearity:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975d2876",
   "metadata": {},
   "source": [
    "## 4.1 Correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b0688e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_df = pd.concat([numerical_df, y], axis=1)\n",
    "numerical_df_balanced = pd.concat([numerical_df_balanced, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad86ccee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_corr1 = numerical_df.corr()\n",
    "data_corr2 = numerical_df_balanced.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b376f49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "sns.heatmap(data_corr1, annot=True, fmt='.2f', linewidths=0.75, cmap='coolwarm')\n",
    "plt.title('Correlation Heat Map for Original dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1544f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "sns.heatmap(data_corr2, annot=True, fmt='.2f', linewidths=0.75, cmap='coolwarm')\n",
    "plt.title('Correlation Heat Map for Balanced dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc627b34",
   "metadata": {},
   "source": [
    "In the balanced dataset, the correlation seems strong may be because now the classes are balanced. But let's see how it goes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b55672",
   "metadata": {},
   "source": [
    "## 4.2 Multi-Collinearity (VIF):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4b2f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_df = numerical_df.drop(columns='churn')\n",
    "numerical_df_balanced = numerical_df_balanced.drop(columns='churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa82bf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = numerical_df.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(numerical_df.values, i) for i in range(numerical_df.shape[1])]\n",
    "\n",
    "vif_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8247c0b6",
   "metadata": {},
   "source": [
    "There is no any feature that has VIF above the threshold of 10, else it would be considered having `Multi-collinearity.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc39721",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(x='feature', height='VIF', data=vif_data)\n",
    "plt.title('VIF values for Mult-collinearity Check')\n",
    "plt.axhline(y=10, color='red', linestyle='--', linewidth=1, label='Threshold (VIF=10)')\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"VIF Value\")\n",
    "plt.title(\"VIF Values for Multicollinearity Check Original Data\")\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5f3a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = numerical_df_balanced.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(numerical_df_balanced.values, i) for i in range(numerical_df_balanced.shape[1])]\n",
    "\n",
    "vif_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fdcac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(x='feature', height='VIF', data=vif_data)\n",
    "plt.title('VIF values for Mult-collinearity Check')\n",
    "plt.axhline(y=10, color='red', linestyle='--', linewidth=1, label='Threshold (VIF=10)')\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"VIF Value\")\n",
    "plt.title(\"VIF Values for Multicollinearity Check(balanced data)\")\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e9b9b5",
   "metadata": {},
   "source": [
    "# 5. Spot Checking Algorithms:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ee8702",
   "metadata": {},
   "source": [
    "Sometimes the model might perform well on the data that is not scaled and sometimes not, so here, I will be Spot checking some classification models on both, scaled and unscaled data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0c8831",
   "metadata": {},
   "source": [
    "## 5.1 Original dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4aea9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5957ed03",
   "metadata": {},
   "source": [
    "### Unscaled data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759cc443",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "models.append(('LR', LogisticRegression(class_weight='balanced', max_iter=3000)))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('SVM', SVC()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('KNN', KNeighborsClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef68ea24",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=7)\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold,scoring=['accuracy', 'precision', 'recall', 'f1'])\n",
    "    \n",
    "    results.append({\n",
    "        'name': name,\n",
    "        'accuracy': cv_results['test_accuracy'].mean(),\n",
    "        'precision': cv_results['test_precision'].mean(),\n",
    "        'recall': cv_results['test_recall'].mean(),\n",
    "        'f1': cv_results['test_f1'].mean()\n",
    "    })\n",
    "    \n",
    "    names.append(name)\n",
    "\n",
    "    \n",
    "    print(f\"{name}: Mean Accuracy: {cv_results['test_accuracy'].mean():.4f}, \"\n",
    "          f\"Precision: {cv_results['test_precision'].mean():.4f}, \"\n",
    "          f\"Recall: {cv_results['test_recall'].mean():.4f}, \"\n",
    "          f\"F1 Score: {cv_results['test_f1'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078bc86a",
   "metadata": {},
   "source": [
    "These `F1-score` are not so good and `SVM` gave 0 which shows how sensitive is it to unscaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5bbc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f978ee",
   "metadata": {},
   "source": [
    "### Scaled Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde02195",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = []\n",
    "\n",
    "pipelines.append(('ScaledLR', Pipeline([('Scaler', StandardScaler()),\n",
    "                                       ('LR', LogisticRegression())])))\n",
    "\n",
    "pipelines.append(('ScaledLDA', Pipeline([('Scaler', StandardScaler()),                                         \n",
    "                                        ('LDA', LinearDiscriminantAnalysis())])))\n",
    "\n",
    "pipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()),                                          \n",
    "                                         ('CART', DecisionTreeClassifier())])))\n",
    "\n",
    "pipelines.append(('ScaledSVM', Pipeline([('Scaler', StandardScaler()),                                         \n",
    "                                        ('SVM', SVC())])))\n",
    "\n",
    "pipelines.append(('ScaledNB', Pipeline([('Scaler', StandardScaler()),                                        \n",
    "                                       ('NB', GaussianNB())])))\n",
    "\n",
    "pipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()),\n",
    "                                        ('KNN', KNeighborsClassifier())])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fa3d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in pipelines:\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=7)\n",
    "    cv_result = cross_val_score(model, X_train, y_train, cv=kfold, scoring=['accuracy', 'precision', 'recall', 'f1'])\n",
    "    \n",
    "    results.append({\n",
    "        'name': name,\n",
    "        'accuracy': cv_results['test_accuracy'].mean(),\n",
    "        'precision': cv_results['test_precision'].mean(),\n",
    "        'recall': cv_results['test_recall'].mean(),\n",
    "        'f1': cv_results['test_f1'].mean()\n",
    "    })\n",
    "    \n",
    "    names.append(name)\n",
    "\n",
    "    \n",
    "    print(f\"{name}: Mean Accuracy: {cv_results['test_accuracy'].mean():.4f}, \"\n",
    "          f\"Precision: {cv_results['test_precision'].mean():.4f}, \"\n",
    "          f\"Recall: {cv_results['test_recall'].mean():.4f}, \"\n",
    "          f\"F1 Score: {cv_results['test_f1'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefa6dd7",
   "metadata": {},
   "source": [
    "`SVM` went from 0 to 0.566 on Scaled-data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6763d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "fig.suptitle(\"Algorithm Comparison\")\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6bc961",
   "metadata": {},
   "source": [
    "### Ensemble Models:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28472ed",
   "metadata": {},
   "source": [
    "Enesemble models are robust to unscaled data, so I wont't be scaling the data here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dedc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembles = [\n",
    "    ('AB', AdaBoostClassifier()),\n",
    "    ('GBM', GradientBoostingClassifier()),\n",
    "    ('RF', RandomForestClassifier()),\n",
    "    ('ET', ExtraTreesClassifier(class_weight='balanced'))\n",
    "]\n",
    "\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "for name, model in ensembles:\n",
    "    kfold = KFold(n_splits=10, random_state=42, shuffle=True)  \n",
    "    cv_results = cross_validate(model, X_train, y_train, cv=kfold, scoring=['accuracy', 'precision', 'recall', 'f1'])\n",
    "\n",
    "    \n",
    "    results.append({\n",
    "        'name': name,\n",
    "        'accuracy': cv_results['test_accuracy'].mean(),\n",
    "        'precision': cv_results['test_precision'].mean(),\n",
    "        'recall': cv_results['test_recall'].mean(),\n",
    "        'f1': cv_results['test_f1'].mean()\n",
    "    })\n",
    "    \n",
    "    names.append(name)\n",
    "\n",
    "    \n",
    "    print(f\"{name}: Mean Accuracy: {cv_results['test_accuracy'].mean():.4f}, \"\n",
    "          f\"Precision: {cv_results['test_precision'].mean():.4f}, \"\n",
    "          f\"Recall: {cv_results['test_recall'].mean():.4f}, \"\n",
    "          f\"F1 Score: {cv_results['test_f1'].mean():.4f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87995fb",
   "metadata": {},
   "source": [
    "#### Still no any good results, so now, lets move into the balanced dataset that was achieved using oversampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ee39c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2b46317",
   "metadata": {},
   "source": [
    "## 5.2 Balanced Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aa47e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, \n",
    "                                                    test_size=0.2, random_state=42, \n",
    "                                                    stratify=y_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5a4070",
   "metadata": {},
   "source": [
    "### Unscaled Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bdc7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "models.append(('LR', LogisticRegression(class_weight='balanced', max_iter=3000)))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('SVM', SVC()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('KNN', KNeighborsClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83e95f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=7)\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=['accuracy', 'precision', 'recall', 'f1'])\n",
    "    \n",
    "    results.append({\n",
    "        'name': name,\n",
    "        'accuracy': cv_results['test_accuracy'].mean(),\n",
    "        'precision': cv_results['test_precision'].mean(),\n",
    "        'recall': cv_results['test_recall'].mean(),\n",
    "        'f1': cv_results['test_f1'].mean()\n",
    "    })\n",
    "    \n",
    "    names.append(name)\n",
    "\n",
    "    \n",
    "    print(f\"{name}: Mean Accuracy: {cv_results['test_accuracy'].mean():.4f}, \"\n",
    "          f\"Precision: {cv_results['test_precision'].mean():.4f}, \"\n",
    "          f\"Recall: {cv_results['test_recall'].mean():.4f}, \"\n",
    "          f\"F1 Score: {cv_results['test_f1'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeb45f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1396619",
   "metadata": {},
   "source": [
    "### Scaled Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45101f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = []\n",
    "\n",
    "pipelines.append(('ScaledLR', Pipeline([('Scaler', StandardScaler()),\n",
    "                                       ('LR', LogisticRegression())])))\n",
    "\n",
    "pipelines.append(('ScaledLDA', Pipeline([('Scaler', StandardScaler()),                                         \n",
    "                                        ('LDA', LinearDiscriminantAnalysis())])))\n",
    "\n",
    "pipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()),                                          \n",
    "                                         ('CART', DecisionTreeClassifier())])))\n",
    "\n",
    "pipelines.append(('ScaledSVM', Pipeline([('Scaler', StandardScaler()),                                         \n",
    "                                        ('SVM', SVC())])))\n",
    "\n",
    "pipelines.append(('ScaledNB', Pipeline([('Scaler', StandardScaler()),                                        \n",
    "                                       ('NB', GaussianNB())])))\n",
    "\n",
    "pipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()),\n",
    "                                        ('KNN', KNeighborsClassifier())])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc864b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in pipelines:\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=7)\n",
    "    cv_result = cross_val_score(model, X_train, y_train, cv=kfold, scoring=['accuracy', 'precision', 'recall', 'f1'])\n",
    "    \n",
    "    \n",
    "    results.append({\n",
    "        'name': name,\n",
    "        'accuracy': cv_results['test_accuracy'].mean(),\n",
    "        'precision': cv_results['test_precision'].mean(),\n",
    "        'recall': cv_results['test_recall'].mean(),\n",
    "        'f1': cv_results['test_f1'].mean()\n",
    "    })\n",
    "    \n",
    "    names.append(name)\n",
    "\n",
    "    \n",
    "    print(f\"{name}: Mean Accuracy: {cv_results['test_accuracy'].mean():.4f}, \"\n",
    "          f\"Precision: {cv_results['test_precision'].mean():.4f}, \"\n",
    "          f\"Recall: {cv_results['test_recall'].mean():.4f}, \"\n",
    "          f\"F1 Score: {cv_results['test_f1'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfe7945",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "fig.suptitle(\"Algorithm Comparison\")\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e48cacf",
   "metadata": {},
   "source": [
    "### Ensemble Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cd32a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembles = [\n",
    "    ('AB', AdaBoostClassifier()),\n",
    "    ('GBM', GradientBoostingClassifier()),\n",
    "    ('RF', RandomForestClassifier()),\n",
    "    ('ET', ExtraTreesClassifier(class_weight='balanced'))\n",
    "]\n",
    "\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "for name, model in ensembles:\n",
    "    kfold = KFold(n_splits=10, random_state=42, shuffle=True)  \n",
    "    cv_results = cross_validate(model, X_train, y_train, cv=kfold, scoring=['accuracy', 'precision', 'recall', 'f1'])\n",
    "\n",
    "    \n",
    "    results.append({\n",
    "        'name': name,\n",
    "        'accuracy': cv_results['test_accuracy'].mean(),\n",
    "        'precision': cv_results['test_precision'].mean(),\n",
    "        'recall': cv_results['test_recall'].mean(),\n",
    "        'f1': cv_results['test_f1'].mean()\n",
    "    })\n",
    "    \n",
    "    names.append(name)\n",
    "\n",
    "    \n",
    "    print(f\"{name}: Mean Accuracy: {cv_results['test_accuracy'].mean():.4f}, \"\n",
    "          f\"Precision: {cv_results['test_precision'].mean():.4f}, \"\n",
    "          f\"Recall: {cv_results['test_recall'].mean():.4f}, \"\n",
    "          f\"F1 Score: {cv_results['test_f1'].mean():.4f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adcc077",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "churn_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
